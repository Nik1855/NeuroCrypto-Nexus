import requests
import logging
from textblob import TextBlob
from transformers import pipeline
from configs.api_config import API_CONFIG
from neuro_utils.crypto_tools import clean_text


class SentimentIntegrator:
    @staticmethod
    def fuse_multiple_sources(symbol):
        """–ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –∏–∑ 10+ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        sources = {
            "twitter": SentimentIntegrator.analyze_twitter(symbol),
            "reddit": SentimentIntegrator.analyze_reddit(symbol),
            "news": SentimentIntegrator.analyze_news(symbol),
            "telegram": SentimentIntegrator.analyze_telegram(symbol),
            "github": SentimentIntegrator.analyze_github(symbol),
            "discord": SentimentIntegrator.analyze_discord(symbol),
            "coingecko": SentimentIntegrator.analyze_coingecko(symbol),
            "tradingview": SentimentIntegrator.analyze_tradingview(symbol)
        }

        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ
        weights = {
            "twitter": 0.25, "reddit": 0.20, "news": 0.15,
            "telegram": 0.15, "github": 0.05, "discord": 0.05,
            "coingecko": 0.10, "tradingview": 0.05
        }

        total = 0
        weight_sum = 0
        for src in sources:
            if sources[src] is not None:
                total += sources[src] * weights[src]
                weight_sum += weights[src]

        sentiment_score = total / weight_sum if weight_sum > 0 else 0
        logging.info(f"–°–≤–æ–¥–Ω—ã–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –¥–ª—è {symbol}: {sentiment_score:.2f}")
        return sentiment_score

    @staticmethod
    def analyze_twitter(symbol):
        """–ê–Ω–∞–ª–∏–∑ Twitter —Å NLP —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–º"""
        try:
            # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Hugging Face –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            nlp = pipeline(
                "sentiment-analysis",
                model="cardiffnlp/twitter-roberta-base-sentiment-latest"
            )

            # –°–±–æ—Ä —Ç–≤–∏—Ç–æ–≤ (—Ä–µ–∞–ª—å–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Twitter API)
            tweets = [
                f"{symbol} is going to the moon! üöÄ",
                f"Concerned about {symbol} recent dip",
                f"New partnership announced for {symbol}"
            ]

            sentiments = []
            for tweet in tweets:
                cleaned = clean_text(tweet)
                result = nlp(cleaned)[0]
                score = SentimentIntegrator.convert_label_to_score(
                    result['label'], result['score']
                )
                sentiments.append(score)

            return sum(sentiments) / len(sentiments) if sentiments else 0
        except Exception as e:
            logging.error(f"Twitter –∞–Ω–∞–ª–∏–∑ –æ—à–∏–±–∫–∞: {e}")
            return 0

    @staticmethod
    def convert_label_to_score(label, confidence):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –º–µ—Ç–∫–∏ –≤ —á–∏—Å–ª–æ–≤–æ–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å"""
        label_map = {"positive": 1, "neutral": 0, "negative": -1}
        base_score = label_map.get(label.lower(), 0)
        return base_score * confidence

    @staticmethod
    def analyze_reddit(symbol):
        """–ê–Ω–∞–ª–∏–∑ Reddit —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
        return 0.15

    @staticmethod
    def analyze_news(symbol):
        """–ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π —Å –ø–æ–º–æ—â—å—é NLP"""
        # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
        return 0.20